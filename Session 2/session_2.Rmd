---
title: "Session 2"
output: html_document
---

Last time, we spent some effort looking at Mark's data.  This time, Maya has been kind enought to donate some of her data for the greater good.  She's already sent me her csv as well as the script she's used for the work.  I'm going to zip through some of her pre-processing first.  I'll stop to highlight a couple of things along the way, though.  We're doing all this with the objective of describing how to plot to find relationships (both how to do it and what to look for) as well as how to run a basic ANOVA and what doing such a thing means.  But first, a word about outliers.

### Outliers
There seems to be a fair amount of ambiguity around how an analyst ought to deal with outliers.  In particular, there are a few options which are often suggested:

1.  Exclude them.
2.  Ignore that they exist.
3.  Run analyses with and without and pray that it doesn't make any difference.

None of these are wrong, *per se*, but I think applying any kind of blanket rule to the question of what to do about outliers is, in general, not a wise choice.  If you're confronted with a situation in which you have a data point or two that are much different than the rest of your data, the best thing you can do is to think carefully about *why* they are different.  The answer might be in your data, it might be in notes to your experiment, or it might require some detective work of another sort altogether.  Your answer to the question of why a particular observation is an outlier should also lead you toward what to do about it.

For instance, if a data point is different because it has been mis-entered (e.g. a research assistant typed 300 rather than 30), you may then decide to fix the problem in one of two ways - either fix it or remove it.  Fixing it will only be possible if you are *sure* of what the real value should be.

On the other hand, you might have an observation which is different just because the person who contributed that datapoint behaved *much* differently than anyone else.  In this scenario, the question you might ask yourself is, 'did this person experience the same experiment that everyone else did?'  If the answer to that is yes, then it shouldn't matter if they behaved much differently than everyone else - their experience is just as meaningful to your research as is someone who scored much closer to the center of the distribution.  If, on the other hand, they experienced a different experiment - perhaps they didn't follow instructions, or the experimenter made a mistake - then in this case, you should almost certainly exclude this data.

Essentially, you never want to throw away good information.  If your outlier is good information, then you should keep it.  You might consider some type of transformation of the data such that your models are better behaved (e.g. take the natural log).

##Maya's data

```{r, warning=FALSE, message=FALSE}
srp <- read.csv('../Data/SR.Past.Rel.12.10.14.csv')
#### EXCLUSIONS ####
#exclude 5 who copied the Michael text verbatim (exclcopied=1)
srp <- srp[ which(is.na(srp$exclcopied) == TRUE ), ]
#exclude 11 who used 'Michael' in their message (didn't follow directions) (exclmich=1)
srp <- srp[ which(is.na(srp$exclmich) == TRUE ), ]

####### COMPUTING VARIABLES ##########
attach(srp)
## rmq
srp$loc <- (rmq_1 + rmq_3 + rmq_4 + rmq_5 + rmq_8 + rmq_16 + rmq_21 + 
              rmq_25 + rmq_28 + rmq_29 + (7-rmq_13) + (7-rmq_24))/12
srp$ass <- ((7-rmq_2) + rmq_6 + rmq_7 + rmq_9 + (7-rmq_10) + rmq_11 + 
              rmq_15 + rmq_19 + rmq_20 + rmq_22 + (7-rmq_27) + rmq_30)/12
srp$locomassess = srp$loc-srp$ass

srp$prom = (6-rfq_1) + rfq_3 + rfq_7 + (6-rfq_9) + rfq_10 + (6-rfq_11)
srp$prev = (6-rfq_2) + (6-rfq_4) + rfq_5 + (6-rfq_6) + (6-rfq_8)
srp$prommprev = srp$prom-srp$prev

# closeness measure
srp$closeness <- (((8-close_1) + (8-close_2) + close_3 + close_4 + 
                     (8-close_5) + (8-close_6) + close_7 + close_8)/8)

# ntoBelong
srp$belong = ((6-NTB_1) + (6-NTB_3) + (6-NTB_7) + NTB_2 + NTB_4 + 
                NTB_5 + NTB_6 + NTB_8 + NTB_9 + NTB_10)/10

# Relational Trust
srp$reltrust = (reltrust_1 + reltrust_2 + reltrust_3 + reltrust_4)/4

# Epistemic Trust
srp$epistrust = (epistrust_1 + epistrust_2 + epistrust_3 + epistrust_4)/4

# message trust
srp$messtrust = (messtrust_1 + messtrust_2 + messtrust_3 + messtrust_4)/4

# ECR
srp$anx = (ECR.S_2 + ECR.S_4 + ECR.S_6 + (8-ECR.S_8) + ECR.S_10 + ECR.S_12)
srp$avoid = ((8-ECR.S_1) + ECR.S_3 + (8-ECR.S_5) + ECR.S_7 + ECR.S_9 + ECR.S_11)

#SCS
srp$independence = (((8-SCS_1) + (8-SCS_2) + (8-SCS_3) + (8-SCS_4) + 
                       (8-SCS_5) + (8-SCS_6) + (8-SCS_7) + (8-SCS_8) + 
                       (8-SCS_9) + (8-SCS_10) + (8-SCS_11) + (8-SCS_12) + 
                       SCS_13 + SCS_14 + SCS_15 + SCS_16 + SCS_17 + SCS_18 + 
                       SCS_19 + SCS_20 + SCS_21 + SCS_22 + SCS_23 + SCS_24)/24)

detach(srp)

#F-Scale
srp$authority = (((srp$F.Scale_1) + (srp$F.Scale_2) + (srp$F.Scale_3) + 
                    (srp$F.Scale_4) + (srp$F.Scale_5) + (srp$F.Scale_6) + 
                    (srp$F.Scale_7) + (srp$F.Scale_8) + (srp$F.Scale_9) + 
                    (srp$F.Scale_10) + (srp$F.Scale_11) + (srp$F.Scale_12) + 
                    srp$F.Scale_13 + srp$F.Scale_14 + srp$F.Scale_15 + 
                    srp$F.Scale_16 + srp$F.Scale_17 + srp$F.Scale_18 + 
                    srp$F.Scale_19 + srp$F.Scale_20 + srp$F.Scale_21 + 
                    srp$F.Scale_22)/22)


#### RECODING ####

####renaming manipulations 
#install.packages("reshape")
library(reshape)
library(reshape)
srp <- rename(srp, c(DO.BR.FL_19="relprime")) #dissolved=1, stable=2
srp <- rename(srp, c(DO.BR.FL_20="attitude")) #like=2, dislike=1
```

The first place I'll stop is here.  Maya is creating a couple of new variables, both coded as zero and one.

```{r, eval=FALSE}

# dummy coding manipulations
srp$relprimedum[srp$relprime == "Stable Relationship Priming"] <- 0
srp$relprimedum[srp$relprime == "Dissolved Relationship Priming"] <- 1

srp$attitudedum[srp$attitude == "Michael-Dislike"] <- 0
srp$attitudedum[srp$attitude == "Michael-Like"] <- 1
```

However, this might not be necessary.  I haven't looked ahead in her code, but R is pretty good at dealing with factor variables.  It usually knows what to do with them and one usually need not explicitly code them as zero and one.  After doing this, she goes on to create several new subsets of data, as defined by these factor variables, so that she can make some histograms of vmessage and vrecall.

```{r, eval=FALSE}
###### SUBSETTING ####
srlike <- subset(srp, attitudedum==1)
srdislike <- subset(srp, attitudedum==0)
srstable <- subset(srp, relprimedum==0)
srdissolve <- subset(srp, relprimedum==1)

library(ggplot2)
theme_set(theme_bw(base_size = 14)) #for all graphs to have bw background & same font size

ggplot(srlike, aes(x=vmessage)) + 
  geom_density()
ggplot(srdislike, aes(x=vmessage)) + 
  geom_density()
ggplot(srstable, aes(x=vmessage)) + 
  geom_density()
ggplot(srdissolve, aes(x=vmessage)) + 
  geom_density()

ggplot(srlike, aes(x=vrecall)) + 
  geom_density()
ggplot(srdislike, aes(x=vrecall)) + 
  geom_density()
ggplot(srstable, aes(x=vrecall)) + 
  geom_density()
ggplot(srdissolve, aes(x=vrecall)) + 
  geom_density()
```

As far as letting us look at our variables to see if they're normally distributed within these subgroups, this approach works okay.  However, the whole thing could be dramatically simplified, and also give us the added bonus of allowing us to see how these distributions change by group.  This is a similar approach to what we were doing with Mark's data.

```{r}
library(ggplot2)
plot <- ggplot(srp, aes(x=vmessage, color=relprime))
plot + geom_density()
```

I've used the original relprime variable to split the distribution into two density curves.  No need to factor, subset, and create separate plots.  We can do the same for vrecall, and we can also repeat the whole thing for attitude:

```{r}
plot <- ggplot(srp, aes(x=vrecall, color=relprime))
plot + geom_density()
```

```{r}
plot <- ggplot(srp, aes(x=vmessage, color=attitude))
plot + geom_density()
```

```{r}
plot <- ggplot(srp, aes(x=vrecall, color=attitude))
plot + geom_density()
```

Now, since we seem to be splitting the data according to the attitude and relprime variable, I'm guessing these are manipulations or covariates that we're interested in.  Let's simplify this plotting even further by faceting the plot.

```{r}
plot <- ggplot(srp, aes(x=vrecall, color=attitude))
plot + geom_density() + facet_wrap(~relprime)
```

```{r}
plot <- ggplot(srp, aes(x=vmessage, color=attitude))
plot + geom_density() + facet_wrap(~relprime)
```

Oookay, that last one is a bit weird.  Seems like nearly 1/2 of that subset of the sample must have given the same rating?

```{r}
table(srp$vmessage, srp$attitude, srp$relprime)
```

Yeah, this lists 9 people who used .5 in that offending group.  Although unusual, it doesn't seem like anything fishy is going on here.

Next, Maya computes some correlation coefficients.  I think the idea here is right, and you'll want to know these coefficients for writing up the results, but what we're seeking here is *understanding*, right?  I've always felt better about looking at data, rather than figuring out what a one-number summary means.  Time to bust out our good friend, the scatter plot.  First, the overall pattern.  I've added a slight jitter to the points so that we can see if any are plotted right on top of each other (a common problem when dealing with scales which have only a few response options)

```{r}
plot <- ggplot(srp, aes(x=vmessage, y=vrecall))
plot + geom_point(position=position_jitter())
```

A pretty clear, strong, positive relationship.  Now let's look at the same pattern by subsets:

```{r}
plot <- ggplot(srp, aes(x=vmessage, y=vrecall))
plot + geom_point(position=position_jitter()) + facet_grid(attitude~relprime)
```

All of these seem to be similar to the overall pattern.  Maybe Dissolved/Dislike is a slightly weaker relationship than the others?  This also shows that the Like attitude seems to have boosted both variables, don't you think?  See how the points are clustered closer to the upper right for the bottom two plots?  Again, this might not pan out in the proper analyses, but if something is going to show up, that's probably going to be it.

###Recap

##### When you have an outlier, think about why it is what it is.

Don't throw away good information.

##### Look at your data!

Really can't emphasize this enough.